{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Neural Network for Predicting Pedestrians Velocity"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This notebook is the pipeline we used to preprocess dataset, train neural network and collect useful training results. Multiple settings of the neural network use the same pipeline here. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# import all the required packages\r\n",
    "import os\r\n",
    "import datetime\r\n",
    "import tensorboard\r\n",
    "from torch.utils.tensorboard import SummaryWriter\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "import torch\r\n",
    "import torchvision\r\n",
    "import pytorch_lightning as pl\r\n",
    "\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.optim as optim\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "%load_ext autoreload\r\n",
    "%autoreload 2\r\n",
    "%matplotlib inline\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Run this line if the notebook crashed when plotting something"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Data Preparation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Path"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "root = os.getcwd()\r\n",
    "vadere_dataset_path = os.path.join(root, \"dataset\", \"vadere_generated\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Device"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "print(\"Using the device\",device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using the device cuda:0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Preprocessing: Set contain_sk=True if training the network with the info of sk (NN1); contain_sk=False without sk(NN2)\r\n",
    "Check codes: utils\\vadereOutputLoader.py"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### The following codes load a trial dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from utils.vadereOutputLoader import vadereOutputLoader\r\n",
    "\r\n",
    "nameOfDataset = \"trial_data.txt\"\r\n",
    "numOfNeighbours = 3\r\n",
    "contain_sk = True\r\n",
    "numOfCols = 4 + 2*numOfNeighbours - (not contain_sk)\r\n",
    "\r\n",
    "vadereRawdataLoader = vadereOutputLoader(vadere_dataset_path, vadere_dataset_path)\r\n",
    "vadereRawdata, sk = vadereRawdataLoader.loadData(nameOfDataset, numOfNeighbours, need_processing=True, contain_sk=contain_sk, return_sk=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### The following codes load the bottlenect datasets."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from utils.vadereOutputLoader import vadereOutputLoader\r\n",
    "\r\n",
    "dataset_name_list = [\"bottleneck_070.txt\", \"bottleneck_095.txt\",\r\n",
    "                     \"bottleneck_120.txt\", \"bottleneck_180.txt\"]\r\n",
    "numOfNeighbours = 10\r\n",
    "contain_sk = True\r\n",
    "numOfCols = 4 + 2*numOfNeighbours - (not contain_sk)\r\n",
    "\r\n",
    "vadereRawdataLoader = vadereOutputLoader(\r\n",
    "    vadere_dataset_path, vadere_dataset_path)\r\n",
    "vadereRawdata, sk = vadereRawdataLoader.mergeDataset(\r\n",
    "    dataset_name_list, \"merged_bottleneck.txt\", numOfNeighbours, need_processing=True, contain_sk=contain_sk, return_sk=True)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "vadereRawdata.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(17819, 22)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "sk.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(17819,)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Customized Dataset class and Dataloaders: \r\n",
    "Check codes: utils\\crowdDataset.py"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "from utils.crowdDataset import crowdDataset\r\n",
    "\r\n",
    "total = len(vadereRawdata)\r\n",
    "np.random.seed(118010142)\r\n",
    "randidx = np.arange(total)\r\n",
    "np.random.shuffle(randidx)\r\n",
    "\r\n",
    "train_idx = np.arange(int(total*.6))\r\n",
    "val_idx = np.arange(int(total*.6), int(total*.8))\r\n",
    "test_idx = np.arange(int(total*.8), total)\r\n",
    "\r\n",
    "\r\n",
    "train = crowdDataset(vadereRawdata[train_idx], device)\r\n",
    "val = crowdDataset(vadereRawdata[val_idx], device)\r\n",
    "test = crowdDataset(vadereRawdata[test_idx], device)\r\n",
    "\r\n",
    "batch_size = 16\r\n",
    "trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\r\n",
    "valloader = torch.utils.data.DataLoader(val, batch_size=batch_size, shuffle=False)\r\n",
    "testloader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Training Neural Network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "%tensorboard --logdir lightning_logs"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Define the network\r\n",
    "A simple example network is shown here. Modify the following block to construct different network structure."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from utils.network import FullyConnectedNet\r\n",
    "\r\n",
    "hparams = {\r\n",
    "    \"numOfLayers\": 1,\r\n",
    "    \"layerSize\": [3],\r\n",
    "    \"learning_rate\": 0.0001\r\n",
    "}\r\n",
    "\r\n",
    "model = FullyConnectedNet(hparams=hparams, input_size=vadereRawdata.shape[1]-1, output_size=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\r\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\r\n",
    "\r\n",
    "# default logger used by trainer\r\n",
    "logger = TensorBoardLogger(\r\n",
    "    save_dir=os.getcwd(),\r\n",
    "    version=model.version,\r\n",
    "    name='lightning_logs'\r\n",
    ")\r\n",
    "\r\n",
    "early_stop_callback = EarlyStopping(\r\n",
    "    monitor = \"val_loss\",\r\n",
    "    patience = 5,\r\n",
    "    verbose = False,\r\n",
    "    mode = \"max\"\r\n",
    ")\r\n",
    "\r\n",
    "trainer = pl.Trainer(\r\n",
    "    max_epochs=50,\r\n",
    "    progress_bar_refresh_rate=25,\r\n",
    "    gpus=1,\r\n",
    "    callbacks=[early_stop_callback],\r\n",
    "    logger = logger\r\n",
    ")\r\n",
    "trainer.fit(model, train_dataloader=trainloader, val_dataloaders=valloader)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | criterion | MSELoss    | 0     \n",
      "1 | model     | ModuleList | 70    \n",
      "-----------------------------------------\n",
      "70        Trainable params\n",
      "0         Non-trainable params\n",
      "70        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Linnore\\anaconda3\\envs\\tf\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:103: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f'The dataloader, {name}, does not have many workers which may be a bottleneck.'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0:   3%|▎         | 25/892 [00:00<00:06, 132.63it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Linnore\\anaconda3\\envs\\tf\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:103: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f'The dataloader, {name}, does not have many workers which may be a bottleneck.'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0: 100%|██████████| 892/892 [00:04<00:00, 210.89it/s, loss=0.139, v_num=0954]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Linnore\\anaconda3\\envs\\tf\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:611: LightningDeprecationWarning: Relying on `self.log('val_loss', ...)` to set the ModelCheckpoint monitor is deprecated in v1.2 and will be removed in v1.4. Please, create your own `mc = ModelCheckpoint(monitor='your_monitor')` and use it as `Trainer(callbacks=[mc])`.\n",
      "  \"Relying on `self.log('val_loss', ...)` to set the ModelCheckpoint monitor is deprecated in v1.2\"\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 5: 100%|██████████| 892/892 [00:02<00:00, 316.48it/s, loss=0.111, v_num=0954]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "trainer.log_dir"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'d:\\\\GitHub\\\\MLCMS-Final-Project\\\\lightning_logs\\\\1_3_20210713-200954'"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "trainer.logged_metrics"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'epoch': tensor(5.),\n",
       " 'val_loss': tensor(0.1033),\n",
       " 'train_loss': tensor(0.0474, device='cuda:0')}"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Output summary of the trained model: "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "if contain_sk:\r\n",
    "    summary_folder_path = os.path.join(root, \"NN1_model_summary\")\r\n",
    "else:\r\n",
    "    summary_folder_path = os.path.join(root, \"NN2_model_summary\")\r\n",
    "\r\n",
    "vhat = model(torch.tensor(vadereRawdata[test_idx, 1:], dtype=torch.float32)).detach().numpy().reshape(-1)\r\n",
    "v = torch.tensor(vadereRawdata[test_idx, 0], dtype=torch.float32).detach().numpy()\r\n",
    "\r\n",
    "model.output_summary(v, vhat, sk[test_idx], trainer.logged_metrics, \"B\", \"B\", summary_folder_path)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-a00cea4c93c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msummary_folder_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"NN2_model_summary\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mvhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvadereRawdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvadereRawdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2460654ee56ca8d86b85b1c440cecfee1406c38df29bb2203e77324a57256ce"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('tf': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}