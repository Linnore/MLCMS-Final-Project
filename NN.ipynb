{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Neural Network for Predicting Pedestrians Velocity"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# import all the required packages\r\n",
    "import os\r\n",
    "import datetime\r\n",
    "import tensorboard\r\n",
    "from torch.utils.tensorboard import SummaryWriter\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "import torch\r\n",
    "import torchvision\r\n",
    "import pytorch_lightning as pl\r\n",
    "\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.optim as optim\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "%load_ext autoreload\r\n",
    "%autoreload 2\r\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Data Preparation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Path"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "root = os.getcwd()\r\n",
    "vadere_dataset_path = os.path.join(root, \"dataset\", \"vadere_generated\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Device"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "print(\"Using the device\",device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using the device cuda:0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Preprocessing: \r\n",
    "Check codes: utils\\vadereOutputLoader.py"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### The following codes load a trial dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from utils.vadereOutputLoader import vadereOutputLoader\r\n",
    "\r\n",
    "nameOfDataset = \"trial_data.txt\"\r\n",
    "numOfNeighbours = 3\r\n",
    "contain_sk = True\r\n",
    "numOfCols = 4 + 2*numOfNeighbours - (not contain_sk)\r\n",
    "\r\n",
    "vadereRawdataLoader = vadereOutputLoader(vadere_dataset_path, vadere_dataset_path)\r\n",
    "vadereRawdata = vadereRawdataLoader.loadData(nameOfDataset, numOfNeighbours, need_processing=True, contain_sk=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### The following codes load the bottlenect datasets."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "dataset_name_list = [\"bottleneck_070.txt\", \"bottleneck_095.txt\",\r\n",
    "                     \"bottleneck_120.txt\", \"bottleneck_180.txt\"]\r\n",
    "numOfNeighbours = 10\r\n",
    "contain_sk = True\r\n",
    "numOfCols = 4 + 2*numOfNeighbours - (not contain_sk)\r\n",
    "\r\n",
    "vadereRawdataLoader = vadereOutputLoader(\r\n",
    "    vadere_dataset_path, vadere_dataset_path)\r\n",
    "vadereRawdata = vadereRawdataLoader.mergeDataset(\r\n",
    "    dataset_name_list, \"merged_bottleneck.txt\", numOfNeighbours, need_processing=True, contain_sk=True)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Customized Dataset class and Dataloaders: \r\n",
    "Check codes: utils\\crowdDataset.py"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "from utils.crowdDataset import crowdDataset\r\n",
    "\r\n",
    "total = len(vadereRawdata)\r\n",
    "randidx = np.arange(total)\r\n",
    "np.random.shuffle(randidx)\r\n",
    "\r\n",
    "train = crowdDataset(vadereRawdata[:int(total*.75)], device)\r\n",
    "val = crowdDataset(vadereRawdata[int(total*.75):], device)\r\n",
    "#test = crowdDataset(vadereRawdata[int(total*.8):], device)\r\n",
    "\r\n",
    "batch_size = 32\r\n",
    "trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\r\n",
    "valloader = torch.utils.data.DataLoader(val, batch_size=batch_size, shuffle=False)\r\n",
    "#testloader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Training Neural Network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "%tensorboard --logdir runs"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Define the network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "from utils.network import FullyConnectedNet\r\n",
    "\r\n",
    "hparams = {\r\n",
    "    \"numOfLayers\": 1,\r\n",
    "    \"layerSize\": [4],\r\n",
    "    \"learning_rate\": 0.0001\r\n",
    "}\r\n",
    "\r\n",
    "model = FullyConnectedNet(hparams=hparams, input_size=numOfCols-1, output_size=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\r\n",
    "\r\n",
    "trainer = pl.Trainer(\r\n",
    "    max_epochs=20,\r\n",
    "    progress_bar_refresh_rate=25,\r\n",
    "    gpus=1,\r\n",
    "    callbacks=[EarlyStopping(monitor=\"val_loss\", patience=5)]\r\n",
    ")\r\n",
    "\r\n",
    "trainer.fit(model, train_dataloader=trainloader,val_dataloaders=valloader)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | criterion | MSELoss    | 0     \n",
      "1 | model     | ModuleList | 101   \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 19: 100%|██████████| 491/491 [00:01<00:00, 302.59it/s, loss=0.154, v_num=5]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Output summary of the trained model: "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "if contain_sk:\r\n",
    "    summary_file_path = os.path.join(root, \"NN1_model_summary.txt\")\r\n",
    "else:\r\n",
    "    summary_file_path = os.path.join(root, \"NN2_model_summary.txt\")\r\n",
    "    \r\n",
    "model.output_summary(len(val), trainer.logged_metrics, \"B\", \"B\", summary_file_path)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "d:\\GitHub\\MLCMS-Final-Project\\model_summary.txt exists, model summary will be attached to the end of this file.\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2460654ee56ca8d86b85b1c440cecfee1406c38df29bb2203e77324a57256ce"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('tf': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}